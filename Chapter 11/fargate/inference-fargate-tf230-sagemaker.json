{
	"requiresCompatibilities": [
		"FARGATE"
	],
    "memory": "8192",
    "cpu": "4096",
	"containerDefinitions": [{
		"command": [
			"mkdir -p /test && cd /test && git clone https://gitlab.com/juliensimon/test-models.git && tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=1 --model_base_path=/test/test-models/model" ],
		"entryPoint": [
			"sh",
			"-c"
		],
		"name": "dlc-tf-inference",
		"image": "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.2-cpu-py37-ubuntu18.04", 
		"essential": true,
		"portMappings": [{
				"hostPort": 8500,
				"protocol": "tcp",
				"containerPort": 8500
			},
			{
				"hostPort": 8501,
				"protocol": "tcp",
				"containerPort": 8501
			}
		],
		"logConfiguration": {
			"logDriver": "awslogs",
			"options": {
				"awslogs-group": "awslogs-tf-ecs",
				"awslogs-region": "eu-west-1",
				"awslogs-stream-prefix": "inference"
			}
		}
	}],
	"volumes": [],
	"networkMode": "awsvpc",
	"placementConstraints": [],
	"family": "inference-fargate-tf230",
    "executionRoleArn": "arn:aws:iam::ACCOUNT_NUMBER:role/ecsTaskExecutionRole"
}
